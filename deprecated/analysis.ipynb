{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from network import resnet18\n",
    "from dataset import create_dataloaders_missing_class,create_dataloaders_uniform_sampling\n",
    "from config import dotdict\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "DEVICE = \"cuda:0\"\n",
    "from torchmetrics import Accuracy, ConfusionMatrix\n",
    "from network import NormConstrainedResNet\n",
    "from trainer import AdamWOptimConfig, CosineAnnealingLRSchedulerConfig, TrainerSettings, Trainer, count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_angle(model1,model2):\n",
    "    X = torch.rand(10,3,32,32).to(DEVICE)\n",
    "    W1 = model1.W.data\n",
    "    W2 = model2.W.data\n",
    "    theta_w = torch.acos(F.cosine_similarity(W1.T,W2.T,dim=1)) * 180 / math.pi   #what are the angles of W1 and W2\n",
    "\n",
    "    Z1 = model1.resnet(X)\n",
    "    Z1 = Z1 @ W1 @ W1.mT  #projection to the subspace spanned by W\n",
    "    Z2 = model2.resnet(X)\n",
    "    Z2 = Z2 @ W2 @ W2.mT  #projection to the subspace spanned by W\n",
    "    theta_z = torch.acos(F.cosine_similarity(Z1.T,Z2.T,dim=1)) * 180 / math.pi\n",
    "    return theta_z,theta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0693, -0.0739, -0.0033,  ..., -0.0272, -0.0681, -0.0118],\n",
       "         [ 0.0382,  0.0135, -0.0876,  ..., -0.0139,  0.0090, -0.0753],\n",
       "         [-0.0021, -0.0068,  0.0302,  ..., -0.0165,  0.0620, -0.0009],\n",
       "         ...,\n",
       "         [ 0.0755,  0.0060, -0.0440,  ..., -0.0625, -0.0028,  0.0015],\n",
       "         [ 0.0147, -0.0255, -0.0178,  ..., -0.0231,  0.0086,  0.0911],\n",
       "         [-0.0051, -0.0946, -0.0185,  ...,  0.0563, -0.0043,  0.0196]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0693, -0.0739, -0.0033,  ..., -0.0272, -0.0681, -0.0118],\n",
       "         [ 0.0382,  0.0135, -0.0876,  ..., -0.0139,  0.0090, -0.0753],\n",
       "         [-0.0021, -0.0068,  0.0302,  ..., -0.0165,  0.0620, -0.0009],\n",
       "         ...,\n",
       "         [ 0.0755,  0.0060, -0.0440,  ..., -0.0625, -0.0028,  0.0015],\n",
       "         [ 0.0147, -0.0255, -0.0178,  ..., -0.0231,  0.0086,  0.0911],\n",
       "         [-0.0051, -0.0946, -0.0185,  ...,  0.0563, -0.0043,  0.0196]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = NormConstrainedResNet(num_classes=10).to(DEVICE)      \n",
    "checkpoint = torch.load(\"models/model_no_norm_WR.pt\", map_location=DEVICE)\n",
    "model1.load_state_dict(checkpoint['model_state_dict'])\n",
    "model2 = NormConstrainedResNet(num_classes=10).to(DEVICE)    \n",
    "checkpoint = torch.load(\"models/model_no_norm_W1.pt\", map_location=DEVICE)\n",
    "model2.load_state_dict(checkpoint['model_state_dict'])\n",
    "#compute_angle(model1,model2)\n",
    "W1 = model1.W.data\n",
    "W2 = model2.W.data\n",
    "W1,W2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., nan, 0., 0., 0., nan, nan, 0., 0., 0., nan, nan, 0., 0., 0., 0., 0., 0., 0., nan],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(20,3,32,32).to(DEVICE)\n",
    "Z1 = model1.resnet(X) @ W1\n",
    "Z1 /= torch.norm(Z1,dim=1,keepdim=True)\n",
    "Z2 = model2.resnet(X) @ W2\n",
    "Z2 /= torch.norm(Z2,dim=1,keepdim=True)\n",
    "torch.acos(F.cosine_similarity(Z1,Z2,dim=1)) * 180 / math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Checking the Unlearning metrics from models trained on all 3 unlearning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from network import resnet18\n",
    "\n",
    "from dataset import create_dataloaders_missing_class,create_dataloaders_uniform_sampling\n",
    "from config import dotdict\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "DEVICE = \"cuda:1\"\n",
    "from torchmetrics import Accuracy, ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load network\n",
    "net = resnet18(num_classes=10)\n",
    "net.load_state_dict(torch.load(\"/research/hal-gaudisac/unlearning/models/model_scratch_resnet18.pt\", map_location=torch.device(DEVICE)))\n",
    "net.to(DEVICE)\n",
    "net.eval()\n",
    "\n",
    "#load unlearn network\n",
    "unlearn_net = resnet18(num_classes=10)\n",
    "unlearn_net.load_state_dict(torch.load(\"/research/hal-gaudisac/unlearning/models/model_NN_resnet18.pt\", map_location=torch.device(DEVICE)))\n",
    "unlearn_net.to(DEVICE)\n",
    "unlearn_net.eval()\n",
    "\n",
    "finetune_net = resnet18(num_classes=10)\n",
    "finetune_net.load_state_dict(torch.load(\"models/model_finetune_resnet18.pt\", map_location=torch.device(DEVICE)))\n",
    "finetune_net.to(DEVICE)\n",
    "finetune_net.eval()\n",
    "\n",
    "scrubs_net = resnet18(num_classes=10)\n",
    "scrubs_net.load_state_dict(torch.load(\"/research/hal-gaudisac/unlearning/models/model_scrubs_resnet18.pt\", map_location=torch.device(DEVICE)))\n",
    "scrubs_net.to(DEVICE)\n",
    "scrubs_net.eval()\n",
    "\n",
    "\n",
    "#load data\n",
    "data_settings = dotdict({\"BATCH_SIZE\": 128, \"data\":{\"num_workers\": 4}, \"DATA_PATH\":\"data\",\"remove_class\":0})\n",
    "#dataloaders = create_dataloaders_missing_class(data_settings)\n",
    "dataloaders = create_dataloaders_uniform_sampling(data_settings)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "#to not load everything in memory\n",
    "dataloaders.forget.pin_memory=False\n",
    "dataloaders.val.pin_memory=False\n",
    "dataloaders.retain.pin_memory=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrain - forget : => 0.012000024318695068\n",
      "retrain - retain : => 0.009000003337860107\n",
      "retrain - val : => 0.19249999523162842\n",
      "unlearn - forget : => 0.18524444103240967\n",
      "unlearn - retain : => 0.15420001745224\n",
      "unlearn - val : => 0.24424999952316284\n",
      "finetune - forget : => 0.19691109657287598\n",
      "finetune - retain : => 0.10240000486373901\n",
      "finetune - val : => 0.24787497520446777\n",
      "scrubs - forget : => 0.3575778007507324\n",
      "scrubs - retain : => 0.26759999990463257\n",
      "scrubs - val : => 0.36262500286102295\n"
     ]
    }
   ],
   "source": [
    "acc = Accuracy(\"multiclass\",num_classes=10).to(DEVICE)\n",
    "cm = ConfusionMatrix(\"multiclass\",num_classes=10).to(DEVICE)\n",
    "\n",
    "cms = []\n",
    "for name,model in [(\"retrain\",net),(\"unlearn\",unlearn_net),(\"finetune\",finetune_net),(\"scrubs\",scrubs_net)]: #\n",
    "    for dl_name,dl in zip([\"forget\",\"retain\",\"val\"],[dataloaders.forget,dataloaders.retain,dataloaders.val]):\n",
    "        acc.reset()\n",
    "        cm.reset()\n",
    "        for batch_id,batch in enumerate(dl):\n",
    "            #if dl_name == \"val\":\n",
    "            #    inputs,targets = inputs[targets!=0], targets[targets!=0]\n",
    "            inputs,targets = batch[0].to(DEVICE),batch[1].to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = (outputs,targets)\n",
    "            acc.update(outputs,targets)\n",
    "            cm.update(outputs,targets)    \n",
    "        print(f\"{name} - {dl_name} : => {1 - acc.compute()}\")\n",
    "    val_cm = cm.compute().detach().cpu().numpy() \n",
    "    cms.append(val_cm/(val_cm.sum(axis=1,keepdims=True)+1))  #compute frobenius norm of confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24147937450130905, 0.2263611036755208, 0.6427778583371856)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(cms[0] - cms[1]),np.linalg.norm(cms[0] - cms[2]),np.linalg.norm(cms[0] - cms[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "with open(\"data/celeba/identity_CelebA.txt\")    as f:\n",
    "    identity_CelebA = pd.read_csv(f, sep=\" \", header=None)\n",
    "identity_CelebA.columns = [\"image_id\", \"identity\"]\n",
    "#randomly sample 10% of identities\n",
    "index = np.random.choice(identity_CelebA[\"identity\"].unique(), 10, replace=False) \n",
    "#assign these index 1 and rest 0\n",
    "identity_CelebA[\"identity\"] = identity_CelebA[\"identity\"].apply(lambda x: 1 if x in index else 0)\n",
    "\n",
    "#save df in the text file like list_forget_partition.txt \n",
    "with open(\"data/celeba/list_forget_partition.txt\", \"w\") as f:\n",
    "    for i in range(len(identity_CelebA)):\n",
    "        f.write(f\"{identity_CelebA.iloc[i,0]} {identity_CelebA.iloc[i,1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta  = {}\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"data/celeba/list_attr_celeba.txt\") as f:\n",
    "    attr_celeba = pd.read_csv(f, sep=\"\\s+\", skiprows=1)\n",
    "attr_celeba.replace(to_replace=-1, value=0, inplace=True)\n",
    "meta = {\"columns\": attr_celeba.columns.tolist(), \"mean\":json.loads(attr_celeba.mean(axis=0).to_json())}\n",
    "with open(\"data/celeba/meta.json\",\"w\") as f:\n",
    "    f.write(json.dumps(meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work with torch unbind\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "X = torch.randn(32, 40, 2)\n",
    "Y = torch.randint(2,(32, 40))\n",
    "tList = [loss_fn(x_i,y_i) for x_i, y_i in zip(torch.unbind(X,dim=1),torch.unbind(Y,dim=1)) ]\n",
    "\n",
    "_, preds = torch.max(X, dim=-1)\n",
    "torch.argmax(X, dim=-1)\n",
    "attr_celeba.columns[19]\n",
    "a = torch.rand(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD CODE for ploting losses and understanding metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def accuracy(pds,tgts):\n",
    "    return torch.mean((torch.max(pds,dim=1)[1]==tgts).float())\n",
    "\n",
    "pds,tgts,ls = [],[],[]\n",
    "dataloaders.forget.pin_memory=False\n",
    "dataloaders.val.pin_memory=False\n",
    "dataloaders.retain.pin_memory=False\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for batch_id, (inputs, targets,mask) in enumerate(dataloaders.forget):\n",
    "    inputs,targets = inputs.to(DEVICE),targets.to(DEVICE)\n",
    "    outputs = net(inputs)\n",
    "    loss = (outputs,targets)\n",
    "    ls.append(loss_fn(outputs,targets).detach().cpu())\n",
    "    pds.append(F.softmax(outputs,dim=1))\n",
    "    tgts.append(targets)\n",
    "pds = torch.cat(pds)\n",
    "tgts = torch.cat(tgts)\n",
    "ls = torch.cat(ls)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "val_pds,val_tgts,val_ls = [],[],[]\n",
    "for batch_id, (inputs, targets,mask) in enumerate(dataloaders.retain):\n",
    "    inputs,targets = inputs.to(DEVICE),targets.to(DEVICE)\n",
    "    outputs = net(inputs)\n",
    "    val_ls.append(loss_fn(outputs,targets).detach().cpu())\n",
    "    val_pds.append(F.softmax(outputs,dim=1))\n",
    "    val_tgts.append(targets)\n",
    "    \n",
    "val_pds = torch.cat(val_pds)\n",
    "val_tgts = torch.cat(val_tgts)\n",
    "val_ls = torch.cat(val_ls)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "normal_pds,normal_tgts,normal_ls = [],[],[]\n",
    "for batch_id, (inputs, targets,mask) in enumerate(dataloaders.val):\n",
    "    inputs,targets = inputs.to(DEVICE),targets.to(DEVICE)\n",
    "    outputs = net(inputs)\n",
    "    normal_ls.append(loss_fn(outputs,targets).detach().cpu())\n",
    "    normal_pds.append(F.softmax(outputs,dim=1))\n",
    "    normal_tgts.append(targets)\n",
    "normal_ls = torch.cat(normal_ls)\n",
    "normal_tgts = torch.cat(normal_tgts)\n",
    "normal_pds = torch.cat(normal_pds)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds,tgts,ls = [],[],[]\n",
    "for batch_id, (inputs, targets,mask) in enumerate(dataloaders.forget):\n",
    "    inputs,targets = inputs.to(DEVICE),targets.to(DEVICE)\n",
    "    outputs = net(inputs)\n",
    "    loss = (outputs,targets)\n",
    "    ls.append(loss_fn(outputs,targets).detach().cpu())\n",
    "    pds.append(F.softmax(outputs,dim=1))\n",
    "    tgts.append(targets)\n",
    "pds = torch.cat(pds)\n",
    "tgts = torch.cat(tgts)\n",
    "ls = torch.cat(ls)\n",
    "\n",
    "\n",
    "from plots import plot_losses\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 6))\n",
    "test_losses = val_pds.max(dim=1)[0].detach().cpu().numpy()\n",
    "forget_losses = normal_pds.max(dim=1)[0].detach().cpu().numpy()\n",
    "X = (test_losses, forget_losses)\n",
    "weights = (np.ones_like(test_losses)/len(test_losses),\n",
    "            np.ones_like(forget_losses)/len(forget_losses))\n",
    "labels = (\"Non Training class\", \"Train classes\")\n",
    "bins = np.histogram(np.hstack(X), bins=20)[1]  # get the bin edges\n",
    "\n",
    "ax1.hist(X, density=False, alpha=0.5, bins=bins,\n",
    "    weights=weights, label=labels)\n",
    "\n",
    "ax1.set_ylabel(\"Percentage Samples\", fontsize=12)\n",
    "ax1.set_xlabel(\"Confidence\", fontsize=12)\n",
    "ax1.legend(frameon=False, fontsize=8)\n",
    "\n",
    "\n",
    "test_losses = val_ls.detach().cpu().numpy()\n",
    "forget_losses = normal_ls.detach().cpu().numpy()\n",
    "X = (test_losses, forget_losses)\n",
    "weights = (np.ones_like(test_losses)/len(test_losses),\n",
    "            np.ones_like(forget_losses)/len(forget_losses))\n",
    "labels = (\"Non Training class\", \"Train classes\")\n",
    "bins = np.histogram(np.hstack(X), bins=20)[1]  # get the bin edges\n",
    "\n",
    "\n",
    "ax2.hist(X, density=False, alpha=0.5, bins=bins,\n",
    "    weights=weights, label=labels)\n",
    "ax2.set_xlabel(\"Cross entropy loss\", fontsize=12)\n",
    "ax2.legend(frameon=False, fontsize=8)\n",
    "plt.savefig('results/scratch_loss.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class re\n",
    "#class specific layers for resnet.\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class ClassAttentionBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_planes: int, out_planes: int, kernel_size: int = 3, stride: Optional[int] = None, groups: int = 1, padding: Optional[str] = \"same\"):\n",
    "        super().__init__()\n",
    "        #here groups are nothing but num of classes\n",
    "        #inplanes -> outplanes -> attention. \n",
    "\n",
    "        \"\"\"\n",
    "        self.height = fmap_size[0]\n",
    "        self.width = fmap_size[1]\n",
    "        \n",
    "        \"\"\"\n",
    "        num_classes  = groups\n",
    "        self.scale = out_planes ** -0.5\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n",
    "                               groups=groups, padding=1, dilation=1, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        #inplanes outplanes dim,num_classes,fmap_size =(32,32)\n",
    "        self.to_qkv = nn.Conv2d(out_planes,out_planes* 3, 1, bias=False,groups=num_classes)\n",
    "        self.class_mask = -torch.ones(num_classes,1,out_planes,out_planes,requires_grad =False)*torch.inf\n",
    "        self.attn_mask = torch.zeros(num_classes,1,out_planes,out_planes,requires_grad =False)\n",
    "        for i in range(num_classes):\n",
    "            self.class_mask[i,:,i*out_planes:(i+1)*out_planes,i*out_planes:(i+1)*out_planes] = 0\n",
    "            self.attn_mask[i,:,i*out_planes:(i+1)*out_planes,i*out_planes:(i+1)*out_planes] = 1\n",
    "        \n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        height, width = out.shape[-2:]\n",
    "\n",
    "        # [batch (heads*3*dim_head) height width]\n",
    "        qkv = self.to_qkv(out)\n",
    "       \n",
    "        # decompose heads and merge spatial dims as tokens\n",
    "        q, k, v = tuple(rearrange(qkv, 'b (d k h) x y  -> k b h d (x y)', k=3, h=1))\n",
    "        # i, j refer to tokens\n",
    "       \n",
    "        dot_prod = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "        if y is not None:\n",
    "            dot_prod += self.attn_mask[y]\n",
    "        \n",
    "        attention = torch.softmax(dot_prod, dim=-1)\n",
    "        if y is not None:\n",
    "            attention *= self.attn_mask[y]\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attention, v)\n",
    "        # Merge heads and decompose tokens to spatial dims\n",
    "        out = rearrange(out, 'b h d (x y) -> b (h d) x y', x=height, y=width)\n",
    "        return out\n",
    "    \n",
    "#class specific layers for resnet.\n",
    "class ClassSpedificResNetBlock(nn.Module):\n",
    "    def __init__(self,in_planes: int, out_planes: int,num_classes:int, kernel_size: int = 3, stride: Optional[int] = None, groups: int = 1, padding: Optional[str] = \"same\") -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv3D\n",
    "        #assert out_planes % num_classes == 0, \"out_planes should be divisible by num_classes\"\n",
    "        self.conv1 = ClassAttentionBlock(in_planes*num_classes, out_planes*num_classes, kernel_size, stride, num_classes, padding)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(in_planes*num_classes, out_planes*num_classes, kernel_size=1, stride=stride, bias=False,groups=num_classes), nn.BatchNorm2d(out_planes*num_classes))\n",
    "\n",
    "        # what if we use LayerNorm instead of BatchNorm.\n",
    "        self.bn1 = nn.BatchNorm2d( out_planes*num_classes)\n",
    "        self.bn2 = nn.BatchNorm2d( out_planes*num_classes)\n",
    "\n",
    "        # activation of relu\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # to match diamensions of x with that of output.\n",
    "        if self.downsample:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        out += x\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 32, 32])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassSpedificResNetBlock(4,8,10, kernel_size= 3,stride=1)\n",
    "x = torch.rand(2,4*10,32,32)\n",
    "y = torch.randint(2,(2,))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 32, 32])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =1\n",
    "w = torch.ones(1,1,80,80)*torch.inf\n",
    "w[:,:,0+y:40+y,0:40] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "dim =8\n",
    "class_mask = torch.ones(num_classes,1,num_classes* dim,num_classes* dim,requires_grad =False)*torch.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.3890e-01,  2.5160e-01,  2.1525e-01,  ...,  2.4397e-01,\n",
       "            3.3694e-01,  2.7881e-01],\n",
       "          [ 2.0173e-01,  3.1196e-01,  3.1179e-02,  ...,  2.9757e-01,\n",
       "            1.4044e-01,  1.1020e-01],\n",
       "          [ 4.7620e-01,  1.0856e-01,  2.5557e-01,  ...,  4.6144e-01,\n",
       "            3.0961e-01,  2.2630e-02],\n",
       "          ...,\n",
       "          [ 4.1908e-01,  2.1499e-01,  9.4574e-02,  ...,  2.0092e-01,\n",
       "            2.3023e-01,  3.7197e-01],\n",
       "          [ 5.1734e-01,  3.0734e-01,  2.1264e-01,  ...,  3.1436e-01,\n",
       "            3.3791e-01,  1.6387e-01],\n",
       "          [ 1.9127e-01,  2.8782e-01,  1.9839e-01,  ...,  1.0235e-01,\n",
       "            3.2376e-01, -7.3516e-03]],\n",
       "\n",
       "         [[ 2.8291e-01,  9.4492e-02,  2.6730e-01,  ...,  1.4632e-01,\n",
       "           -1.4304e-01, -3.9575e-01],\n",
       "          [ 2.9632e-01,  3.5927e-01,  1.9496e-01,  ...,  5.2694e-01,\n",
       "            4.2898e-01, -7.6187e-02],\n",
       "          [ 8.8827e-03, -1.2398e-02,  5.8757e-01,  ...,  3.4401e-01,\n",
       "            4.8196e-01, -1.3220e-01],\n",
       "          ...,\n",
       "          [ 5.5073e-01,  6.1162e-01,  2.0877e-01,  ...,  3.6852e-01,\n",
       "            2.0590e-01, -1.4793e-01],\n",
       "          [ 1.3648e-01,  3.4532e-01,  5.1815e-01,  ...,  1.8871e-01,\n",
       "            7.6592e-01, -1.6055e-01],\n",
       "          [ 3.2614e-01,  5.0194e-01,  2.3836e-01,  ...,  3.5019e-01,\n",
       "            4.0236e-01,  1.5026e-01]],\n",
       "\n",
       "         [[ 2.7537e-01, -1.6898e-01, -8.1706e-02,  ..., -1.9736e-01,\n",
       "           -1.1474e-01, -5.0386e-01],\n",
       "          [ 4.0793e-01, -1.9893e-01,  3.9894e-01,  ...,  1.9389e-02,\n",
       "            2.7233e-01, -1.3283e-01],\n",
       "          [-1.6315e-02, -1.8737e-01, -4.0212e-02,  ...,  6.8662e-02,\n",
       "           -2.9071e-02, -7.9242e-03],\n",
       "          ...,\n",
       "          [ 3.2448e-01,  1.0960e-01, -7.4200e-02,  ..., -3.6471e-01,\n",
       "           -9.6914e-02, -2.0641e-01],\n",
       "          [ 6.3824e-02, -2.5831e-01, -1.0769e-04,  ...,  9.8734e-02,\n",
       "           -1.3726e-01, -1.3231e-01],\n",
       "          [ 2.2283e-01, -8.4677e-02, -2.4750e-02,  ...,  1.3636e-01,\n",
       "           -2.7631e-01,  2.5911e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.0619e-04, -2.8572e-01, -4.1499e-01,  ..., -1.9303e-01,\n",
       "           -4.1177e-01, -3.1194e-01],\n",
       "          [-1.7272e-02, -5.0330e-01, -1.5466e-01,  ..., -7.4054e-01,\n",
       "           -3.5177e-01, -2.6770e-01],\n",
       "          [ 2.0699e-01, -2.1351e-01, -8.6799e-02,  ..., -4.2597e-01,\n",
       "           -4.8085e-01, -1.2467e-01],\n",
       "          ...,\n",
       "          [-9.4973e-04, -3.2842e-01, -4.2285e-01,  ..., -3.6966e-01,\n",
       "           -7.0136e-01, -3.4658e-01],\n",
       "          [-9.8247e-02, -4.5431e-01, -1.9472e-01,  ..., -2.4708e-01,\n",
       "           -5.1449e-01, -3.4068e-01],\n",
       "          [ 9.4978e-02, -7.7343e-02, -7.6563e-02,  ..., -3.0271e-01,\n",
       "           -2.0783e-01, -9.7978e-03]],\n",
       "\n",
       "         [[-1.3358e-01,  4.2071e-01,  3.1088e-01,  ...,  1.3363e-01,\n",
       "            3.1559e-01,  5.0250e-01],\n",
       "          [ 2.1258e-03,  4.0690e-01, -4.8070e-02,  ...,  3.5407e-01,\n",
       "            1.2078e-01,  3.8653e-01],\n",
       "          [-1.4532e-01,  9.1949e-02, -3.9531e-02,  ...,  2.7571e-01,\n",
       "            2.6386e-01,  1.6804e-01],\n",
       "          ...,\n",
       "          [-1.8423e-01, -4.4737e-02,  2.6367e-01,  ..., -5.2766e-02,\n",
       "            2.3351e-01,  5.0325e-01],\n",
       "          [-2.0239e-01,  3.8308e-01,  5.3146e-02,  ...,  1.5676e-01,\n",
       "           -1.6668e-01,  5.8238e-01],\n",
       "          [-9.3523e-02, -2.0069e-02,  1.4875e-01,  ...,  2.6627e-01,\n",
       "            1.5794e-02,  1.7143e-01]],\n",
       "\n",
       "         [[ 4.7461e-02, -3.3126e-01, -4.5628e-01,  ..., -3.8226e-01,\n",
       "           -2.5200e-01, -2.5905e-01],\n",
       "          [ 1.7888e-01, -4.9434e-01, -1.6640e-01,  ...,  1.2229e-01,\n",
       "           -2.5951e-01, -3.1632e-01],\n",
       "          [ 8.9382e-03, -2.8156e-01, -4.2121e-01,  ..., -1.2449e-01,\n",
       "           -2.6091e-01, -2.5568e-01],\n",
       "          ...,\n",
       "          [ 1.0459e-01, -3.4215e-01, -8.6393e-02,  ..., -3.8230e-01,\n",
       "           -3.7201e-01, -5.1105e-01],\n",
       "          [ 2.5397e-01, -3.2209e-01, -2.9658e-01,  ..., -3.0922e-01,\n",
       "           -2.4983e-01, -2.4118e-01],\n",
       "          [-1.6630e-02,  2.7626e-01,  1.4634e-01,  ...,  4.4096e-01,\n",
       "            1.6661e-01, -2.5976e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1434e-01,  3.0185e-01,  2.9337e-01,  ...,  2.5989e-01,\n",
       "            1.6706e-01,  2.1383e-01],\n",
       "          [ 2.9653e-01,  8.8117e-02,  3.4089e-01,  ...,  3.7793e-01,\n",
       "            2.6313e-01,  1.7324e-01],\n",
       "          [ 3.9177e-01,  1.3307e-01,  2.5844e-01,  ...,  4.5280e-01,\n",
       "            5.9019e-02,  8.3720e-02],\n",
       "          ...,\n",
       "          [ 3.9750e-01,  3.5157e-01,  2.2924e-01,  ...,  4.3360e-01,\n",
       "            4.1230e-02,  1.9472e-01],\n",
       "          [ 5.1015e-01,  2.2049e-01,  1.9229e-01,  ...,  3.5657e-02,\n",
       "           -7.0140e-03, -8.4322e-02],\n",
       "          [ 3.0057e-01, -3.2396e-02,  3.5989e-01,  ...,  2.9523e-01,\n",
       "            3.6278e-01,  2.7096e-01]],\n",
       "\n",
       "         [[ 7.1026e-02,  3.1361e-01,  1.5625e-01,  ...,  1.7859e-01,\n",
       "            2.9462e-02, -1.4889e-01],\n",
       "          [ 3.1140e-01,  1.1091e-01,  6.2898e-01,  ...,  4.4661e-01,\n",
       "            4.1231e-01, -3.2205e-02],\n",
       "          [ 3.5472e-01,  4.6613e-01,  4.5005e-01,  ...,  5.6720e-01,\n",
       "            4.1502e-01, -1.8156e-01],\n",
       "          ...,\n",
       "          [ 5.3371e-01,  2.3486e-01,  5.0884e-01,  ...,  2.2994e-01,\n",
       "           -1.3241e-01, -3.5072e-02],\n",
       "          [ 5.3974e-01,  3.1813e-01,  1.8991e-01,  ...,  6.2446e-02,\n",
       "            2.3845e-01, -3.9223e-01],\n",
       "          [ 2.0894e-01,  3.2788e-01,  2.3383e-01,  ...,  4.6263e-01,\n",
       "            3.8783e-01,  1.7439e-01]],\n",
       "\n",
       "         [[ 9.9635e-02, -1.1771e-01, -4.0181e-02,  ..., -3.4783e-01,\n",
       "           -3.2960e-01, -2.3311e-01],\n",
       "          [ 4.5600e-02,  7.6076e-03, -1.0301e-01,  ..., -1.8341e-01,\n",
       "           -3.2655e-01, -2.4003e-01],\n",
       "          [ 3.2184e-01, -2.2562e-01, -2.6068e-01,  ...,  1.9695e-01,\n",
       "           -8.3371e-02, -4.5438e-01],\n",
       "          ...,\n",
       "          [ 6.9320e-02,  2.6506e-01,  1.1045e-02,  ..., -2.6967e-01,\n",
       "           -1.4084e-01, -2.4293e-01],\n",
       "          [ 1.4742e-01,  5.3182e-01, -9.5483e-02,  ...,  2.0662e-02,\n",
       "            1.6372e-02,  6.7467e-02],\n",
       "          [ 1.9938e-02, -1.5135e-02, -8.0185e-02,  ..., -2.3366e-01,\n",
       "            1.0063e-01, -1.4175e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.7794e-01, -3.6431e-01, -4.8559e-01,  ..., -4.7105e-01,\n",
       "           -5.0199e-01, -2.9358e-01],\n",
       "          [-9.9153e-02, -1.7016e-01, -1.1502e-01,  ..., -4.9331e-01,\n",
       "           -1.3987e-01, -3.6561e-01],\n",
       "          [-2.8681e-03,  1.0730e-02, -1.3065e-02,  ..., -2.6238e-01,\n",
       "           -7.4874e-01, -4.1739e-01],\n",
       "          ...,\n",
       "          [ 5.8722e-02, -4.2380e-01, -5.1345e-01,  ..., -3.2853e-01,\n",
       "           -3.9100e-01, -3.3427e-01],\n",
       "          [-5.7801e-02, -4.7203e-01, -3.7859e-01,  ..., -4.0578e-01,\n",
       "           -3.9871e-01, -3.6238e-01],\n",
       "          [-2.0638e-01, -2.2677e-01, -9.6127e-02,  ..., -1.5285e-01,\n",
       "           -2.0099e-01, -8.5818e-02]],\n",
       "\n",
       "         [[-1.2902e-01,  8.9494e-02,  2.5132e-01,  ...,  4.1224e-01,\n",
       "            2.7679e-01,  4.5734e-01],\n",
       "          [-2.2358e-01,  1.2621e-01,  7.2530e-02,  ...,  1.5082e-01,\n",
       "           -1.4090e-02,  4.9438e-01],\n",
       "          [ 1.8070e-02,  1.0907e-01,  3.0172e-01,  ...,  6.4607e-03,\n",
       "            2.5361e-01,  2.4196e-01],\n",
       "          ...,\n",
       "          [-2.9868e-01,  2.7073e-01, -2.1019e-01,  ...,  7.6562e-02,\n",
       "            1.6444e-01,  4.8606e-01],\n",
       "          [-1.0427e-01,  1.0990e-01,  2.4882e-01,  ...,  2.3935e-02,\n",
       "           -7.2515e-02,  4.6859e-01],\n",
       "          [-4.3220e-02,  1.0896e-01,  4.4557e-02,  ...,  1.5332e-02,\n",
       "           -5.5341e-02,  9.7131e-02]],\n",
       "\n",
       "         [[-8.0869e-02, -1.4789e-01, -2.0908e-01,  ..., -5.5479e-01,\n",
       "           -5.0850e-01, -2.3636e-01],\n",
       "          [-1.3600e-01, -1.9599e-01,  9.3834e-02,  ..., -3.8012e-01,\n",
       "           -4.2479e-01, -2.4027e-01],\n",
       "          [-4.4150e-03, -4.5925e-01, -2.1703e-01,  ..., -1.3961e-01,\n",
       "           -3.8119e-01, -2.1126e-01],\n",
       "          ...,\n",
       "          [-1.2781e-01, -1.1449e-01, -5.6180e-01,  ..., -3.6189e-01,\n",
       "           -2.4255e-01, -2.6308e-01],\n",
       "          [ 2.9777e-02, -5.6657e-01,  5.9052e-02,  ..., -2.3865e-01,\n",
       "           -2.8629e-01, -3.2854e-01],\n",
       "          [ 2.5537e-01,  2.4444e-01,  1.5476e-01,  ...,  2.0532e-01,\n",
       "            1.9922e-02, -2.2063e-01]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
