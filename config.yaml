BASE_DIR : "unlearning"
DEVICE : 'cuda:1'
SEED : 42
BATCH_SIZE : 1024
DATA_PATH: 'data'
MODEL_DIR: 'models'

directory:
  RESULT_PATH: 'results'
  LOG_PATH: 'logs'
  LOGGER_PATH: 'logger.log'

data:
  num_workers: 16
  rf_split: [0.1, 0.9]

model:
  name: 'resnet18' 
  model_args:
    num_classes: 10
  #checkpoint: "/research/hal-gaudisac/unlearning/models/weights_resnet18_cifar10.pth"

trainer :
  #checkpoint: '/research/hal-gaudisac/unlearning/models/weigths_resnet18.pt'
  verbose: True
  train: True
  
  log_freq: 10
  epochs: 200

  optimizer: 
    type: 'SGD'
    lr: 0.015
    #momentum: 0.9
    weight_decay: 0.0001
  # optimizer: 
  #   type: 'AdamW'
  #   lr: 0.01
  #   weight_decay: 0.0001
  #   betas: [0.9, 0.999]

  scheduler: 
    type: 'CosineAnnealingLR'
    T_max: 200
    eta_min: 0.0001

attack_model:
  name: 'MLP-grad-mia'
  type: 'MiaModel'
  charecterstic: 'gradients'
  folds: 5
  model_args:
    model_config: [512,128,16,8]
    num_classes: 2
    
attack_trainer: 

  name: 'mia trainer'
  verbose: True
  epochs: 300
  log_freq: 10

  optimizer: 
    type: 'SGD'
    lr: 0.1
    momentum: 0.9
    weight_decay: 0.0001

  scheduler: 
    type: 'CosineAnnealingLR'
    T_max: 300
    eta_min: 0.0001

finetune :
  verbose: True
  train: True
  
  log_freq: 10
  epochs: 50

  # optimizer: 
  #   type: 'AdamW'
  #   lr: 0.01
  #   weight_decay: 0.0001
  #   betas: [0.9, 0.999]

  optimizer: 
    type: 'SGD'
    lr: 0.0015
    #momentum: 0.9
    weight_decay: 0.0001
  scheduler: 
    type: 'CosineAnnealingLR'
    T_max: 50
    eta_min: 0.00001










#model:
#  name: 'ResNet' 
#  model_args:
#    block_config: [[3,64,1],[2,128,2],[2,256,2],[2,512,2]] [(1,8,1),(1,16,2),(1,32,2)] #model with 3 blocks of 16 channels with a stride of 1 and 2 blocks of 32 and 64 channels with a stride of 2 

#training :
#  checkpoint: '/research/hal-gaudisac/unlearning/models/weigths_ResNet_3x64x1-2x128x2-2x256x2-2x512x2.pt'
#  checkpoint: '/research/hal-gaudisac/unlearning/models/weigths_ResNet_1x8x1-1x16x2-1x32x2.pt'


#attack_model:
#  name: 'MLP-grad-mia'
#  type: 'MiaModel' LogisticRegression GradientBoostingClassifier
#  charecterstic: 'gradient' 
#  model_args:
#    model_config: [512,256,128,64,32,16,8] num_iters=1000